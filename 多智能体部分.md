## 多智能体（Multi-Agent）使用说明

本项目已集成多智能体编排：面部情绪识别 → 提示词初稿（LLM）→ 个性化提示词（LLM+DB）→ 文生音乐生成。该流程以可编程方式运行，不会启动 Gradio 网页（除非你单独运行 demo）。

### 架构概览

- Agent1 情绪识别：`tools/face_tool.py`
  - 输入：图片/视频路径（视频取第一帧）
  - 输出：`{"emotion": "fear|disgust|sad|angry", "confidence": float, "extra": {...}}`
- Agent3 初稿提示词（LLM）：`agents/multi_agent.py#agent3_draft_prompt`
  - 使用 Moonshot（OpenAI 兼容），按照模板生成初步音乐描述
- Agent4 个性化提示词（LLM）：`agents/multi_agent.py#agent4_personalize_prompt`
  - 融合用户在 MySQL 中的偏好，输出最终 Prompt 与建议生成参数
- Agent2 文生音乐：`tools/musicgen_tool.py`
  - 复用 `audiocraft-main/demos/musicgen_app.py` 的 `predict_full` 生成音/视频文件

### 目录结构

```
agents/
  multi_agent.py        # 多智能体编排入口（Moonshot LLM 调用、串联四步）
tools/
  face_tool.py          # 面部情绪识别（已接入 Face/ResNet18 + checkpoint）
  musicgen_tool.py      # 调用 predict_full 进行音乐生成
  mysql_repo.py         # MySQL 数据访问封装（可选）
```

### 环境依赖

请在目标虚拟环境中安装：

```
pip install -U "langchain>=0.2.14" "langchain-openai>=0.1.7" "openai>=1.51.0" "sqlalchemy>=2.0" "pymysql"
```

文生音乐依赖参考 `audiocraft-main/requirements.txt`（含 torch/torchaudio/transformers 等）。

### 环境变量（必需/可选）

- Moonshot LLM（必需）
  - `OPENAI_API_KEY`：你的 Moonshot Key
  - `OPENAI_BASE_URL`：`https://api.moonshot.cn/v1`（OpenAI 兼容端点）
- MySQL（可选，开启落库）
  - `DB_HOST`, `DB_USER`, `DB_PASSWORD`, `DB_NAME`, 可选 `DB_PORT`
- Hugging Face 缓存（可选）
  - `HF_HOME`, `HUGGINGFACE_HUB_CACHE`, `TRANSFORMERS_CACHE`, `HF_DATASETS_CACHE`

### 快速开始（编程式调用）

不会启动 Gradio 网页，只会返回音/视频文件路径与中间产物：

```python
from agents.multi_agent import run_multi_agent, GenerationParams

# 仅 LLM + 生成，不带面部素材与落库
res = run_multi_agent(media_path=None, user_id=None, gen_params=GenerationParams(duration=15))
print(res["prompt_initial"])   # 初稿提示词
print(res["prompt_final"])     # 个性化后的最终提示词
print(res["outputs"])          # {"wav": ..., "video": ..., "wav_mbd": ..., "video_mbd": ...}

# 带面部素材 & 可选落库（需配置 DB_* 环境变量且 user_id 存在）
res = run_multi_agent(media_path=r"E:\\path\\to\\image_or_video.jpg", user_id=1)
print(res["emotion"])          # 面部情绪识别结果
print(res["outputs"])          # 生成结果路径
```

### 与 Streamlit 集成（示例）

```python
import streamlit as st
from agents.multi_agent import run_multi_agent, GenerationParams

uploaded = st.file_uploader("上传图片/视频 (可选)")
user_id = st.number_input("用户ID(可选)", value=1)
if st.button("生成音乐"):
    media_path = None
    if uploaded is not None:
        tmp = f"./data_upload/{uploaded.name}"
        with open(tmp, "wb") as f:
            f.write(uploaded.getbuffer())
        media_path = tmp
    res = run_multi_agent(media_path=media_path, user_id=user_id, gen_params=GenerationParams(duration=15))
    st.write(res["emotion"])         # 显示情绪
    st.write(res["prompt_final"])    # 显示最终 Prompt
    if res["outputs"].get("wav"):
        st.audio(res["outputs"]["wav"])
    if res["outputs"].get("video"):
        st.video(res["outputs"]["video"])
```

### Face 模型说明（tools/face_tool.py）

- 自动导入 `Face/models/Resnet18.py` 并从 `Face/RAF_checkpoints_ResNet18_1_200/best/best_model_*.pth` 选择最新权重。
- 类别顺序：`["fear", "disgust", "sad", "angry"]`，如与你的训练定义不一致，请在 `_IDX_TO_EMOTION` 中调整顺序。
- 视频处理取第一帧；若需时序投票/多帧策略，可自行扩展 `_read_image_from_path` 与 `detect_emotion`。

### MySQL 落库

`tools/mysql_repo.py` 提供：

- `create_session(user_id, source)` 创建会话
- `save_emotion(session_id, emotion)` 记录情绪结果
- `save_generation(...)` 保存生成记录（最终 Prompt、参数、音视频路径）
  在 `agents/multi_agent.py` 中，若检测到 DB 环境变量，会自动尝试落库。

### 常见问题

1) 不想启动网页？
   - 直接用 `run_multi_agent(...)`。只有单独运行 `audiocraft-main/demos/musicgen_app.py` 才会启动 Gradio。
2) `gr.make_waveform` 缺失？
   - 已兼容 Gradio 5.x，内部优先用 `gradio_client.media_utils.make_waveform`，否则回退 ffmpeg。
3) Moonshot 连接报错？
   - 确认 `OPENAI_API_KEY`、`OPENAI_BASE_URL=https://api.moonshot.cn/v1`；网络需可访问。
4) CUDA 与 torchaudio 报 DLL 错误？
   - 保证 torch/torchvision/torchaudio 同版本同 CUDA 构建（如 cu121/cu126），统一同源安装。
5) Pydantic 版本冲突？
   - 当前多智能体不依赖 FastAPI/Gradio；若要跑 demo UI，参考已整理的兼容矩阵进行固定。

### 版本与兼容性建议

- LLM：`langchain>=0.2.14`、`langchain-openai>=0.1.7`、`openai>=1.51.0`
- 文生音乐：按 `audiocraft-main/requirements.txt` 建议安装（确保 torch 系列与 CUDA 一致）
- Gradio（仅 UI demo 用）：已做 5.x 兼容；不需要网页交互时可忽略

如需进一步拆分为微服务（独立生成进程/队列），或将 `predict_full` 改造成纯后端函数（去掉 Gradio 依赖），可在此文基础上继续重构。






