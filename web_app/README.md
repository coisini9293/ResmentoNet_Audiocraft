# 🎭 情绪音乐助手 - Web应用

基于Streamlit的情绪识别和音乐生成Web应用，集成了LangChain多智能体系统。

## 功能特性

### 🎯 核心功能

- **面部情绪识别**: 使用ResNet18模型检测4种情绪（恐惧、厌恶、悲伤、愤怒）
- **智能音乐生成**: 基于检测到的情绪生成改善情绪的音乐
- **用户系统**: 完整的用户注册、登录和历史记录管理
- **多智能体系统**: 使用LangChain实现情绪分析和音乐推荐智能体

### 🧠 智能体系统

- **情绪分析智能体**: 分析检测到的情绪，提供心理分析和改善建议
- **音乐推荐智能体**: 根据情绪状态推荐合适的音乐类型和特征

### 📊 数据管理

- **用户管理**: SQLite数据库存储用户信息
- **历史记录**: 保存情绪检测和音乐生成历史
- **系统日志**: 记录所有操作和错误信息

## 项目结构

```
web_app/
├── main.py                 # 主应用文件
├── auth.py                 # 用户认证模块
├── database/
│   └── models.py          # 数据库模型
├── agents/
│   ├── emotion_agent.py   # 情绪分析智能体
│   └── music_agent.py     # 音乐推荐智能体
├── static/                # 静态文件
├── requirements.txt       # 依赖包列表
├── run_app.py            # 启动脚本
└── README.md             # 项目说明
```

## 安装和运行

### 1. 环境要求

- Python 3.8+
- PyTorch 2.0+
- CUDA支持（可选，用于GPU加速）

### 2. 安装依赖

```bash
cd web_app
pip install -r requirements.txt
```

### 3. 配置环境变量

```bash
# 设置OpenAI API密钥（用于智能体）
export OPENAI_API_KEY="your_openai_api_key"

# 设置Suno API密钥（用于音乐生成）
export SUNO_API_KEY="your_suno_api_key"
```

### 4. 启动应用

```bash
# 方法1：使用启动脚本
python run_app.py

# 方法2：直接使用Streamlit
streamlit run main.py
```

### 5. 访问应用

打开浏览器访问: http://localhost:8501

## 使用说明

### 1. 用户注册/登录

- 首次使用需要注册账号
- 支持用户名、密码和邮箱注册
- 密码使用SHA256哈希加密存储

### 2. 情绪检测

- 上传面部图片（支持JPG、JPEG、PNG格式）
- 系统自动检测情绪类型和置信度
- 显示详细的概率分布

### 3. 智能分析

- 情绪分析智能体提供心理分析
- 音乐推荐智能体推荐合适的音乐类型
- 提供情绪改善建议

### 4. 音乐生成

- 基于情绪分析结果生成音乐
- 支持Suno API音乐生成
- 保存生成记录到数据库

### 5. 历史记录

- 查看情绪检测历史
- 查看音乐生成记录
- 查看系统操作日志

## 技术架构

### 前端

- **Streamlit**: Web应用框架
- **自定义CSS**: 美化界面样式
- **响应式设计**: 适配不同屏幕尺寸

### 后端

- **PyTorch**: 深度学习框架
- **ResNet18**: 情绪识别模型
- **SQLite**: 数据存储
- **LangChain**: 智能体框架

### 智能体系统

- **情绪分析智能体**: 使用OpenAI GPT模型
- **音乐推荐智能体**: 专业的音乐推荐逻辑
- **工具集成**: 多种分析工具和推荐算法

## 配置说明

### 模型配置

- 模型路径: `RAF_checkpoints_ResNet18_1_200/best/best_model_70200.pth`
- 支持情绪: Fear, Disgust, Sad, Angry
- 输入尺寸: 3x224x224

### 数据库配置

- 数据库文件: `emotion_music.db`
- 自动创建表结构
- 支持用户、历史记录、日志管理

### API配置

- OpenAI API: 用于智能体对话
- Suno API: 用于音乐生成
- 支持环境变量配置

## 开发说明

### 添加新的智能体

1. 在 `agents/`目录下创建新的智能体文件
2. 继承LangChain的Agent基类
3. 实现必要的工具和方法
4. 在 `main.py`中集成新智能体

### 扩展情绪识别

1. 训练新的模型
2. 更新 `class_names`列表
3. 修改模型加载路径
4. 更新情绪映射逻辑

### 自定义音乐生成

1. 实现新的音乐生成API
2. 更新 `music_generator.py`
3. 添加新的音乐风格映射
4. 集成到主应用中

## 故障排除

### 常见问题

1. **模型加载失败**: 检查模型文件路径和PyTorch版本
2. **智能体初始化失败**: 检查OpenAI API密钥配置
3. **数据库错误**: 检查SQLite权限和文件路径
4. **音乐生成失败**: 检查Suno API密钥和网络连接

### 日志查看

- 应用日志: 查看Streamlit控制台输出
- 系统日志: 在Web界面查看系统日志页面
- 数据库日志: 查看SQLite数据库文件

## 许可证

本项目仅供学习和研究使用。

## 贡献

欢迎提交Issue和Pull Request来改进项目。

## 联系方式

如有问题，请通过GitHub Issues联系。
